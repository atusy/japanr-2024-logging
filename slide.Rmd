---
title: "Happy Structured Logging in R"
author: atusy
output:
  litedown::html_format:
    meta:
      css: ["@default", "@snap"]
      js: ["@snap"]
    options:
      embed_resources: true
---

```{r setup, include=FALSE}
devtools::load_all()
opts <- litedown::reactor()
opts$collapse <- TRUE
opts$dev.args <- list(units = "in", width = 7, height = 2.8, res = 180)
logger::log_appender(logger::appender_stdout)
```

```{js, echo=FALSE}
document.addEventListener('DOMContentLoaded', () => {
  // folding
  const foldCode = Array.from(document.querySelectorAll('code.fold'));
  foldCode.forEach((code) => {
    const parent  = code.parentElement;
    const title = (code.title && code.title !== "") ? code.title : "Code";
    if (parent.tagName === "PRE") {
      parent.outerHTML = `<details><summary><small>${title}</small></summary>${parent.outerHTML}</details>`;
    }
  });
});
```

# Atusy

- Application Engineer at [3-shake Inc.](https://3-shake.com/)
- Maitainer of R packages
  - felp, ftExtra, knitr, rmarkdown, ...
- Appears on
  - Blog: <https://blog.atusy.net/>
  - GitHub: [@atusy](https://github.com/atusy)
  - X: [@Atsushi776](https://x.com/Atsushi776)

---

# Publication

![](http://image.gihyo.co.jp/assets/images/cover/2022/9784297125240.jpg){style="height:6in"}

---

# Why logging?

To record or help identifying (potential) issues and enhance improvements.

- **unexpected behaviors**, typically errors
- **performance issues**
- security issues
- auditing and compliance

The **[logger]** package helps you.

[logger]: https://daroczig.github.io/logger/index.html

---

# Why logging library?

Because `print` is not enough to

- generate analyzable logs
- threshold by severity
- control output destinations
- distinguish program output from logging
    - typically on CLI tools
    - less important in R

Avoid reinvention with `print`, unless intentionally.

---

## Generate analyzable logs

- has timestamp
- has machine readable format
    - i.e. structured logging
- has traceable context
    - especially for asynchronous or distributed systems

---

## Threshold by severity

- For production
    - **FATAL:** when an error stops the program
    - **ERROR:** when an error is caught and program continued running
    - **WARNING:** when an unexpected behavior occurs without error
    - **INFO:** various info for debugging/monitoring purpose
- Additionally for development
    - **DEBUG:** further detailed info for debugging purpose
    
---

## Control output destinations

- stdout
- file
- DB
- SaaS (e.g., Datadog, New Relic, ...)

---

# Log format

---

## What is the preferred format?

Machine readable one, typically **JSON Lines**. \
Then, packages help you parsing the data (e.g., **jsonlite**, **yyjsonr**, ...).

```{r structured-log, echo=FALSE, comment=""}
logger::log_formatter(logger::formatter_json)
logger::log_layout(logger::layout_json_parser(c("time", "level")))
logger::log_info(message = "Program started.")
logger::log_warn(message = "Some warning.")
```

---

## What about human-readable format?

The log requires self-maintained parsers...

```{r traditional-log, echo=FALSE, comment=""}
logger::log_formatter(logger::formatter_logging)
logger::log_layout(logger::layout_logging)
logger::log_info("Program started.")
logger::log_warn("Some warning.")
```

---

## Can we use both?

YES!

- human readable logs to console
- machine readable logs to file

---

# How to log?

---

## Basic

Use **logger** package

```{r, cache = FALSE}
# Configure
logger::log_appender(logger::appender_stdout)
logger::log_formatter(logger::formatter_json)
logger::log_layout(logger::layout_json_parser(c("time", "level", "ns")))
```

```{r, comment=""}
# Log
logger::log_info(message = "Program started.")
```

---

## In Package

- Key points:
  - Configure **logger** with `.onLoad()`
  - Use environment variables to control the behavior
  - Use unique namespace and avoid affect other **logger**s

- Reference materials:
  - [Rのパッケージ内でloggerパッケージを使う](https://blog.atusy.net/2024/11/19/logger-in-r-package/)
  - 例: <https://github.com/atusy/japanr-2024-logging/blob/main/R/zzz.R>

---

## Log Schema?

Should be easy to analyze

| key | type | desc |
| --- | --- | --- |
| time | string | when the log is generated |
| level | string | severity |
| ns | string | namespace |
| message | string | static message |
| session_id | string | unique per access |
| trace_id | string | unique per request |
| span_id | string | unique per task |
| value | any | a value related to the message |
| context | named list | additional context |

---

### Why static message?

easy to analyze (e.g., `dplyr::filter()` and `dplyr::group_by()`)

```{r, comment=""}
x <- 1
logger::log_info(
  message = "x is defined", # not glue::glue("x is {x}")
  value = x
)
````

---

### What are the various identifiers?

- **session_id**
    - R sessions that loads the package
    - browser sessions in Shiny app
- **trace_id**
    - function calls
    - user-interactions in Shiny app
- **span_id**: unique per task
    - various tasks with the same trace_id

These keywords typically appears in observability engineering.

---

### What is the context?

Some additional information that is not suitable for `value`.

---

### What is the value?

value related to the message

```{r, comment=""}
f <- function(x) {
  logger::log_info(message = "f(x) is called", value = x)
}
```

---

# Examples of log analysis

```{r, attr.output=".txt .fold title='Output'"}
logdata <- system.file("extdata/japanr2024.jsonl", package = "japanr2024") |>
  yyjsonr::read_ndjson_file() |>
  dplyr::mutate(time = clock::date_time_parse(time, "Asia/Tokyo")) |>
  dplyr::glimpse()
```

---

## Error count

Oh no! Many requests suffer errors!

```{r, attr.source=".r .fold", cache=FALSE}
logdata |>
  dplyr::summarize(
    time = min(time),
    errors = sum(level == "ERROR"),
    .by = "trace_id"
  ) |>
  ggplot2::ggplot() +
  ggplot2::aes(time, errors) +
  ggplot2::geom_point() +
  ggplot2::scale_x_datetime(name = "", date_breaks = "10 sec")
```

---

## Request response time

Hmm... users have to wait for several seconds...

```{r, attr.source=".r .fold", cache=FALSE}
logdata |>
  dplyr::mutate(start = min(time), .by = "trace_id") |>
  dplyr::reframe(
    start = min(start),
    start_span = time[message == "Received request"],
    end_span = time[message == "Processed request"],
    duration = end_span - start_span,
    locations = lengths(value[message == "Locations parsed"]),
    .by = "trace_id"
  ) |>
  ggplot2::ggplot() +
  ggplot2::aes(start, duration, color = locations) +
  ggplot2::geom_point() +
  ggplot2::scale_x_datetime(name = "", date_breaks = "10 sec") +
  ggplot2::scale_y_continuous() +
  NULL
```



---

## Deep dive into errors and slow responses.

```{r, attr.source=".r .fold", cache=FALSE, dev.args=list(units = "in", width = 7, height = 3.3, res = 180)}
logdata |>
  dplyr::filter(!is.na(span_id)) |>
  dplyr::summarize(
    start = min(time),
    end = max(time),
    location = unlist(value[message == "Processing location"]),
    error = "ERROR" %in% level,
    .by = c("trace_id", "span_id")
  ) |>
  dplyr::mutate(
    location = forcats::fct_relevel(location, rev(unique(location)))
  ) |>
  ggplot2::ggplot() +
  ggplot2::aes(
    x = start, xend = end,
    y = location, yend = location,
    color = error,
  ) +
  ggplot2::geom_segment() +
  ggplot2::facet_grid(rows = "trace_id", scales = "free_y") +
  ggplot2::theme(
    strip.text.y = ggplot2::element_blank(),
    axis.title.x = ggplot2::element_blank()
  ) +
  ggplot2::scale_x_datetime(name = "", date_breaks = "10 sec")
```

---

## Insights from the analysis

- Fast user inputs cause too many requests
    - Same locations are processed multiple times
- Invalid/unsupported locations cause errors
    - they are ignorable

---

# Ideas to solve the issues

---

## Slow down a reactive expression with debounce/throttle

<https://shiny.posit.co/r/reference/shiny/1.9.0/debounce.html>

---

## Memoising slow functions

```{r}
# Memoised versions of openmeteo functions
geocode <- memoise::memoise(openmeteo::geocode)
weather_forecast <- memoise::memoise(
  openmeteo::weather_forecast,
  # Invalidate cache daily
  hash = function(x) rlang::hash(list(x, Sys.Date()))
)

# Efficient forecast function
forecast <- function(x) {
  g <- geocode(x)
  weather_forecast(c(g$latitude, g$longitude), hourly = "temperature_2m")
}
```

## 

---

# ENJOY HAPPY STRUCTURED LOGGING!

- Record logs to identify (potential) issues!
- Use structured logs and analyze them with lovely tidyverse!
